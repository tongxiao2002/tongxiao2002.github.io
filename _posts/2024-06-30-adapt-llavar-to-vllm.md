---
title: vllm æ¨ç†é€‚é…è‡ªå®šä¹‰æ¨¡å‹ (1)
date: 2024-06-30 16:30:00 +0800
categories: [Transformers, Large Language Models]
tags: [vllm, inference]
---

æœ¬æ–‡å¯¹åº”ä»£ç ï¼š[https://github.com/tongxiao2002/vllm-for-LMMs](https://github.com/tongxiao2002/vllm-for-LMMs)

## èƒŒæ™¯

æœ€è¿‘å› ä¸ºç§‘ç ”éœ€æ±‚ï¼Œéœ€è¦æµ‹è¯•ä¸€äº›å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLMMï¼‰åœ¨æŸäº›ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ç”±äºæ˜¯â€œå¤§â€è¯­è¨€æ¨¡å‹ï¼Œå…ä¸äº†éœ€è¦å¤šå¡æ¨ç†ï¼ˆå…¶å®åæ¥å‘ç°ä¹Ÿä¸éœ€è¦ï¼Œ13B æ¨¡å‹å®Œå…¨å¯ä»¥æ­£å¸¸åœ¨ä¸€å¼  A800-80G å¡ä¸Šè·‘...ï¼‰ï¼Œå› æ­¤å°±å°è¯•äº†å¥½å‡ ä¸ªåˆ†å¸ƒå¼è®­ç»ƒ or æ¨ç†æ¡†æ¶ï¼ŒåŒ…æ‹¬ `accelerate`ï¼Œ`deepspeed-inference` ä»¥åŠä»Šå¤©çš„ä¸»è§’ `vllm`ã€‚æˆ‘æœ€å¼€å§‹æƒ³åˆ°çš„å°±æ˜¯ `vllm`ï¼Œå› ä¸ºä¹‹å‰ç”¨ `vllm` åš LLM çš„æ¨ç†ä½“éªŒéå¸¸å¥½ï¼Œæƒ³ç€ LMM ç›¸æ¯” LLM å°±åŠ ä¸ªå›¾è€Œä¸”åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ä¹Ÿæ˜¯å½“ä½œ token å¤„ç†ï¼Œåº”è¯¥å·®åˆ«ä¸å¤§ã€‚ç„¶è€Œçœ‹äº†çœ¼ `vllm` çš„ vlm ç›¸å…³æ–‡æ¡£æ„Ÿè§‰å¾ˆä¸è¯¦ç»†ï¼Œè€Œä¸”æœ‰å¾ˆå¤šæˆ‘éœ€è¦æµ‹è¯•çš„ LMM å¹¶ä¸æ”¯æŒï¼ŒåŒ…æ‹¬ `LLaVAR`ï¼Œ `Qwen-VL` ç­‰ç­‰ã€‚æ‰€ä»¥åˆå›è¿‡å¤´å»è¯•äº†è¯• `accelerate` ä»¥åŠ `deepspeed-inference`ï¼Œè™½ç„¶è¿™ä¸¤å…„å¼Ÿå¾ˆå¥½å®ç°åˆ†å¸ƒå¼æ¨ç†ï¼Œä½†æ˜¯é€Ÿåº¦å®åœ¨å¤ªæ…¢ï¼ŒåŒæ ·çš„ `llava-1.5-7b-hf` å’Œ 600 æ¡æ•°æ®ï¼Œ`deepspeed-inference` éœ€è¦è·‘ 7hï¼Œ`accelerate` å°±æ›´ä¸ç”¨è¯´äº†ï¼Œè€Œ `vllm` åªéœ€è¦ 4minï¼Œé€Ÿåº¦å·®å®åœ¨æ˜¯å¤ªå¤¸å¼ äº†ï¼ˆä¹Ÿå¯èƒ½æ˜¯æˆ‘ `deepspeed` å’Œ `accelerate` ç”¨çš„ä¸å¯¹ğŸ¤”ï¼‰ã€‚æ‰€ä»¥æœ€åè¿˜æ˜¯ç‹ ä¸‹å¿ƒå›æ¥å•ƒ `vllm` æºä»£ç å°è¯•è‡ªå·±åšé€‚é…ã€‚

## å®˜æ–¹æ–‡æ¡£

`vllm` å®˜æ–¹ä¹Ÿç»™å‡ºäº†ä¸€ä¸ªéå¸¸ç²—ç•¥çš„é€‚é…è‡ªå®šä¹‰æ¨¡å‹çš„[æ–‡æ¡£](https://docs.vllm.ai/en/latest/models/adding_model.html)ï¼Œä½†çœ‹è¿™æ„æ€å…¶å®è¿˜æ˜¯å¾—è‡ªå·±å•ƒæºä»£ç ç„¶åè‡ªå·±æ”¹æ‰èƒ½é€‚é…ï¼Œå¹¶æ²¡æœ‰æä¾›ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„æ¥å£ã€‚

å®˜æ–¹æ–‡æ¡£ç»™å‡ºçš„æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹çš„æ­¥éª¤å¯ä»¥åˆ†ä¸º 4 æ­¥ï¼š

1. å°†è‡ªå®šä¹‰æ¨¡å‹çš„ `forward` å‡½æ•°æ¥å£ï¼ˆé€šå¸¸ä¸º `huggingface-transformers` çš„æ¥å£ï¼‰æ”¹ä¸º `vllm` çš„é€šç”¨æ¥å£ï¼š

    ```python
    def forward(
        self,
        input_ids: torch.Tensor,
    -    attention_mask: Optional[torch.Tensor] = None,
    -    position_ids: Optional[torch.LongTensor] = None,
    -    past_key_values: Optional[List[torch.FloatTensor]] = None,
    -    inputs_embeds: Optional[torch.FloatTensor] = None,
    -    labels: Optional[torch.LongTensor] = None,
    -    use_cache: Optional[bool] = None,
    -    output_attentions: Optional[bool] = None,
    -    output_hidden_states: Optional[bool] = None,
    -    return_dict: Optional[bool] = None,
    -) -> Union[Tuple, CausalLMOutputWithPast]:
    +    positions: torch.Tensor,
    +    kv_caches: List[torch.Tensor],
    +    attn_metadata: AttentionMetadata,
    +) -> Optional[SamplerOutput]:
    ```

    é‚£ç°åœ¨æ¥å£å‚æ•°å°±ä»…æœ‰ `input_ids`, `positions`, `kv_caches` å’Œ `attn_metadata`ã€‚
2. ï¼ˆå¯é€‰ï¼‰å°†è‡ªå®šä¹‰æ¨¡å‹ä¸­çš„ Linear Layer ä»¥åŠ Embedding ç­‰æ”¹ä¸ºæ”¯æŒ tensor paralellism çš„å½¢å¼ï¼Œæ¯”å¦‚ `vllm` ä¸­æä¾›çš„ `QKVParallelLinear`, `VocabParallelEmbedding` ç­‰ç­‰ï¼Œä¸ç„¶æ²¡æ³•é€šè¿‡ tensor parallelism è¿›è¡Œå¤šå¡æ¨ç†åŠ é€Ÿã€‚å¦‚æœæ¨¡å‹æœ¬èº«ç‰¹åˆ«å¤§ï¼Œæ¯”å¦‚ `Llama-3-70B` è¿™ç§ï¼Œé‚£å°±å¿…é¡»è¦å®ç°è¿™ä¸€æ­¥ï¼Œä¸ç„¶ä¸€å¼ å¡å¡ä¸ä¸‹æ•´ä¸ªæ¨¡å‹ã€‚
3. é‡å†™ `load_weights` å‡½æ•°ï¼Œç”¨äºä» checkpoints ä¸­åŠ è½½å‚æ•°åˆ°æ¨¡å‹ä¸­ã€‚
4. æ³¨å†Œæ¨¡å‹ï¼Œè®© `vllm.LLM` èƒ½å¤Ÿè¯†åˆ«è‡ªå®šä¹‰æ¨¡å‹å¹¶æ‰§è¡Œï¼š
    ```python
    from vllm import ModelRegistry
    from your_code import YourModelForCausalLM
    ModelRegistry.register_model("YourModelForCausalLM", YourModelForCausalLM)
    ```
è¿™å››æ­¥çœ‹èµ·æ¥æœ€éš¾çš„å…¶å®å°±æ˜¯1ã€2æ­¥ï¼Œå› ä¸ºæ¶‰åŠåˆ°æ¨¡å‹ç»“æ„å’Œ `forward` é€»è¾‘çš„é‡å†™ã€‚æˆ‘ä»Šå¤©ä»¥é€‚é… `LLaVAR` ä¸ºä¾‹è¿›è¡Œè¯´æ˜ï¼Œç”±äº `llava-1.5` æ¨¡å‹æ˜¯ `vllm` åŸç”Ÿæ”¯æŒçš„æ¨¡å‹ï¼Œ`LLaVAR` ä¸ `LLaVA` çš„åŒºåˆ«ä¸»è¦åœ¨äºå‚æ•°çš„åŠ è½½å½¢å¼ä¸åŒä»¥åŠä¸€ç‚¹æ¨¡å‹ç»“æ„ä¸Šçš„åŒºåˆ«ï¼Œç»å¤§éƒ¨åˆ†æ¨¡å‹ç»“æ„å’Œ `forward` é€»è¾‘æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤æœ¬æ–‡å°†ä¸»è¦æ¶‰åŠç¬¬3ã€4æ­¥ï¼Œç¬¬1ã€2æ­¥å°†ç•™åˆ°åé¢æˆ‘éœ€è¦å®ç°ä¸€ä¸ª `vllm` å®Œå…¨ä¸æ”¯æŒçš„æ¨¡å‹å†å†™ã€‚

æœ¬æ–‡è¡Œæ–‡é¡ºåºå¤§è‡´ä¸Šä¼šè·Ÿå®˜æ–¹æ–‡æ¡£ä¸Šå†™çš„ 4 ä¸ªæ­¥éª¤ä¿æŒä¸€è‡´ï¼Œä½†æ˜¯ç”±äºå¾ˆå¤šå…¶ä»–é—®é¢˜çš„å­˜åœ¨ï¼Œå› æ­¤ä¼šåŠ å…¥ä¸€äº›å…¶ä»–å¿…è¦æ­¥éª¤ã€‚

LLaVAR Github Repo: [https://github.com/SALT-NLP/LLaVAR](https://github.com/SALT-NLP/LLaVAR)

LLaVAR HuggingFace Repo: [https://huggingface.co/SALT-NLP/LLaVAR_delta](https://huggingface.co/SALT-NLP/LLaVAR_delta)

## å®ç° `LlavaRForConditionalGeneration` ç±»ï¼Œä¿®æ”¹æ¨¡å‹ç»“æ„

å¦‚ä¸Šæ–‡æ‰€è¿°ï¼Œ`LLaVAR` ç»å¤§éƒ¨åˆ†ä¸ `llava-1.5` ç›¸åŒï¼Œå› æ­¤ç›´æ¥ç»§æ‰¿ `LlavaForConditionalGeneration` ç±»ï¼Œä½†æ˜¯è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œç»§æ‰¿çš„åº”å½“æ˜¯ `vllm` ä¸­å®ç°çš„ç±»ï¼Œå¦åˆ™è¿˜æ˜¯å¾—æ”¹ `forward` é€»è¾‘å’Œæ¨¡å‹ç»“æ„ï¼Œå±äºå¤šæ­¤ä¸€ä¸¾ã€‚

`vllm` ä¸­ `LlavaForConditionalGeneration` ç±»å…·ä½“å®ç°ï¼š[link](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/models/llava.py#L90)

```python
# llavar.py

from vllm.model_executor.models.llava import LlavaForConditionalGeneration
class LLavaRForConditionalGeneration(LlavaForConditionalGeneration):
    def __init__(
        self,
        config: LlavaConfig,
        vision_language_config: VisionLanguageConfig,
        cache_config: CacheConfig | None = None,
        quant_config: QuantizationConfig | None = None
    ) -> None:
        super().__init__(config, vision_language_config, cache_config, quant_config)
```

ç”±äº `LlavaForConditionalGeneration` ç±»å®ç°çš„æ˜¯ `llava-1.5`ï¼Œä½¿ç”¨äº†åŒå±‚ MLP ä½œä¸º multimodal projectorï¼Œè€Œ `LLaVAR` ä½œä¸ºåŸºäº `llava-1.3` çš„æ¨¡å‹ï¼Œä»…ç”¨äº†ä¸€å±‚ Linear Layer ä½œä¸º multimodal projectorï¼Œå› æ­¤éœ€è¦å¯¹è¿™éƒ¨åˆ†æ¨¡å‹ç»“æ„è¿›è¡Œæ”¹å˜ï¼Œå³åˆ é™¤ `LlavaForConditionalGeneration` ç±»ä¸­çš„æˆå‘˜å˜é‡ `self.multi_modal_projector`ï¼Œå¹¶åŠ å…¥ä¸€ä¸ªå•å±‚ Linear Layer çš„ `self.mm_projector`ï¼ˆå–è¿™ä¸ªåå­—è¿™ä¹Ÿæ˜¯ä¸ºäº†å’Œ checkpoints ä¸­çš„åç§°å¯¹åº”ï¼‰ï¼š

```python
# llavar.py

from vllm.model_executor.models.llava import LlavaForConditionalGeneration
class LLavaRForConditionalGeneration(LlavaForConditionalGeneration):
    def __init__(...) -> None
    super().__init__(...)

    delattr(self, "multi_modal_projector")
    self.mm_projector = nn.Linear(
        in_features=config.vision_config.hidden_size,
        out_features=config.text_config.hidden_size,
        bias=True,
    )
```

è‡³æ­¤ï¼Œæ¨¡å‹ç»“æ„å·²ç»ä¿®æ”¹è‡³ä¸ `LLaVAR` æ¨¡å‹ä¸€è‡´ã€‚

## é‡å†™ `load_weights` å‡½æ•°é€»è¾‘

`load_weights` å‡½æ•°æ˜¯ `vllm` ä¸­æ‰€æœ‰æ¨¡å‹éƒ½å…·æœ‰çš„ä¸€ä¸ªæˆå‘˜å‡½æ•°ï¼Œä¼šåœ¨ `vllm.LLM` åˆå§‹åŒ–æ—¶è¢«è°ƒç”¨ï¼Œç”¨äºå°†åŠ è½½ checkpoints ä¸­çš„å‚æ•°åŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚å…·ä½“åœ¨ [`ModelLoader`](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/model_loader/loader.py#L264) è¢«è°ƒç”¨ã€‚è¯¥å‡½æ•°æ¥å—ä¸€ä¸ªç±»ä¼¼äº `state_dict` çš„è¿­ä»£å™¨å‚æ•°ï¼Œè¿­ä»£å™¨ä¸­æ¯ä¸€é¡¹ä¸º (å‚æ•°åï¼ŒTensor) çš„äºŒå…ƒç»„ã€‚é‡å†™è¯¥å‡½æ•°çš„ç›®æ ‡å°±æ˜¯å°†è¿™äº›å‚æ•°åŠ è½½åˆ°æ¨¡å‹ä¸­ï¼Œè¿™ä¸€æ­¥çš„é€»è¾‘ï¼Œä»¥åŠæœ€ç®€å•çš„å®é™…æƒ…å†µå°±æ˜¯æ‹¿åˆ°ä¸€ä¸ª weightsï¼Œç„¶åæ‰¾åˆ°å¯¹åº”çš„ parameterï¼Œç„¶å copy å°±å®Œäº‹äº†ã€‚

`LlavaForConditionalGeneration` ç±»å®ç°çš„ [`load_weights`](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/models/llava.py#L306) é€»è¾‘è¾ƒä¸ºå¤æ‚ï¼ŒåŸå› ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç‚¹ï¼š

1. `llava-1.5-7b-hf` checkpoints ä¸­çš„å‚æ•°åä¸ `vllm` ä¸­å®ç°çš„ `LlavaForConditionalGeneration` ç±»ä¸å¯¹åº”ã€‚æ¯”å¦‚å‡ºäºä¼˜åŒ–çš„ç›®çš„ï¼Œ`LlavaForConditionalGeneration` å°† `llava-1.5-7b-hf` ä¸­ LLaMA self-attention éƒ¨åˆ†çš„ `q_proj`, `k_proj`, `v_proj` ä¸‰ä¸ª Linear Layer åˆå¹¶ä¸ºäº†ä¸€ä¸ª `qkv_proj`ï¼Œä»¥åŠå°† LLaMA MLP éƒ¨åˆ†çš„ `gate_proj` å’Œ `up_proj` åˆå¹¶ä¸ºäº† `gate_up_proj`ï¼Œå› æ­¤éœ€è¦åˆ†å¤šæ¬¡å°†è¿™äº›åˆ†æ•£çš„å‚æ•°åŠ è½½åˆ°å®Œæ•´çš„ `qkv_proj` å’Œ `gate_up_proj` ä¸­ã€‚
2. è¿˜æ˜¯å‡ºäºä¼˜åŒ–çš„ç›®çš„ï¼Œ`QKVParallelLinear`, `VocabParallelEmbedding` ç­‰éƒ¨åˆ†æ˜¯é¢å‘ tensor parallelism å®ç°çš„ï¼Œå› æ­¤æ¯ä¸€ä¸ª worker (æˆ– GPU) éƒ½åªä¼š load checkpoints ä¸­å®Œæ•´å‚æ•°çš„ä¸€éƒ¨åˆ†ã€‚ä¸è¿‡å¥½åœ¨è¿™ç§éƒ¨åˆ†åŠ è½½ `vllm` å·²ç»å¸®æˆ‘ä»¬å®ç°å¥½äº†ã€‚`QKVParallelLinear` å’Œ `VocabParallelEmbedding` ç­‰æ¨¡å—éƒ½æœ‰ä¸€ä¸ª `weight_loader` å‡½æ•°ï¼Œå°±æ˜¯ç”¨äºéƒ¨åˆ†åŠ è½½å‚æ•°ï¼Œä»¥æ”¯æŒ tensor parallelismï¼Œå¦‚ [`QKVParallelLinear.weight_loader`](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/layers/linear.py#L548)ã€‚åœ¨é‡å†™ `load_weights` æ—¶ï¼Œç»å¤§éƒ¨åˆ†æƒ…å†µå¯ä»¥ç›´æ¥è°ƒç”¨ `vllm` å·²å®ç°çš„ `weight_loader` å‡½æ•°ï¼Œä½†æ˜¯ä¹Ÿéœ€è¦å¯¹ `weight_loader` å‡½æ•°æ¥å£è¶³å¤Ÿç†è§£ã€‚

è½åˆ° `LLaVAR` çš„ `load_weights` å…·ä½“å®ç°ï¼Œé¦–å…ˆéœ€è¦çŸ¥é“ checkpoints ä¸­å’Œ `LlavaRForConditionalGeneration` ç±»ä¸­å‚æ•°åçš„åŒºåˆ«ï¼š

`LlavaRForConditionalGeneration` ç±»ä¸­çš„å‚æ•°ç»“æ„ï¼š

```python
- vision_tower
- mm_projector      # åˆšåˆšä¿®æ”¹çš„
-- mm_projector.weight
-- mm_projector.bias
- language_model
-- language_model.embed_tokens
-- language_model.norm
-- language_model.layers.0.self_attn.qkv_proj.weight
-- language_model.layers.0.self_attn.o_proj.weight
-- language_model.layers.0.self_attn.input_layernorm.weight
-- language_model.layers.0.self_attn.post_attention_layernorm.weight
-- language_model.layers.0.mlp.gate_up_proj.weight
-- language_model.layers.0.mlp.down_proj.weight
-- ......
- lm_head
-- lm_head.weight
```

`LLaVAR` æä¾›çš„ checkpoints å‚æ•°ï¼š

```python
- lm_head.weight
- model.norm.weight
- model.mm_projector.weight
- model.mm_projector.bias
- model.embed_tokens.weight
- model.layers.0.input_layernorm.weight
- model.layers.0.mlp.down_proj.weight
- model.layers.0.mlp.gate_proj.weight
- model.layers.0.mlp.up_proj.weight
- model.layers.0.post_attention_layernorm.weight
- model.layers.0.self_attn.q_proj.weight
- model.layers.0.self_attn.k_proj.weight
- model.layers.0.self_attn.v_proj.weight
- model.layers.0.self_attn.o_proj.weight
- model.layers.0.self_attn.rotary_emb.inv_freq
......
```

å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œéœ€è¦åœ¨ `load_weights` å‡½æ•°ä¸­ä¿®æ”¹ä¸‰ä¸ªéƒ¨åˆ†ï¼Œä½¿å¾— weights ä¸ parameters å¯¹é½ï¼š

1. `model.mm_projector` éœ€è¦æ”¹åä¸º `mm_projector`ï¼Œå»æ‰å‰ç¼€ `model.`ï¼›
2. é™¤äº† `mm_projector` æ„å¤–ï¼Œæ‰€æœ‰ä»¥ `model.` å¼€å¤´çš„å‚æ•°åéƒ½å¾—æ”¹ä¸º `language_model.`ï¼›
3. æ‰‹åŠ¨åŠ è½½ `vision_tower`ã€‚å› ä¸º `LLaVAR` æä¾›çš„ checkpoints ä¸­å¹¶æ²¡æœ‰ `vision_tower` çš„å‚æ•°ï¼Œä½†æˆ‘ä»¬çŸ¥é“ `LLaVAR` çš„ `vision_tower` å…¶å®å°±æ˜¯ `openai/clip-vit-large-patch14-336`ï¼Œå› æ­¤æ‰‹åŠ¨åŠ è½½å³å¯ã€‚

å…·ä½“çš„å®ç°åŸºäº `LlavaForConditionalGeneration` ç±»çš„å®ç°åšä¸€äº›ä¿®æ”¹å³å¯ï¼š

```python
# llavar.py

from vllm.model_executor.models.llava import LlavaForConditionalGeneration
from vllm.model_executor.model_loader.weight_utils import default_weight_loader

_KEYS_TO_MODIFY_MAPPING = {
    # Prioritize replacing "model.mm_projector" with "mm_projector" rather than language_model.mm_projector
    # The earlier the position in the mapping dictionary, the higher the priority
    "model.mm_projector": "mm_projector",
    "model.": "language_model.",
}


class LLavaRForConditionalGeneration(LlavaForConditionalGeneration):
    def __init__(...) -> None:
        ...

    def load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]]):
        # only doing this for language model part for now.
        stacked_params_mapping = [
            # (param_name, shard_name, shard_id)
            ("qkv_proj", "q_proj", "q"),
            ("qkv_proj", "k_proj", "k"),
            ("qkv_proj", "v_proj", "v"),
            ("gate_up_proj", "gate_proj", 0),
            ("gate_up_proj", "up_proj", 1),
        ]
        params_dict = dict(self.named_parameters())
        for name, loaded_weight in weights:
            if "rotary_emb.inv_freq" in name:
                continue
            for key_to_modify, new_key in _KEYS_TO_MODIFY_MAPPING.items():
                if key_to_modify in name:
                    name = name.replace(key_to_modify, new_key)
            use_default_weight_loading = False
            if "vision" in name:
                if self.vision_tower is not None:
                    # We only do sharding for language model and
                    # not vision model for now.
                    use_default_weight_loading = True
            else:
                for (param_name, weight_name,
                     shard_id) in stacked_params_mapping:
                    if weight_name not in name:
                        continue
                    param = params_dict[name.replace(weight_name, param_name)]
                    weight_loader = param.weight_loader
                    weight_loader(param, loaded_weight, shard_id)
                    break
                else:
                    use_default_weight_loading = True
            if use_default_weight_loading:
                param = params_dict[name]
                weight_loader = getattr(param, "weight_loader",
                                        default_weight_loader)
                weight_loader(param, loaded_weight)
```

å¯ä»¥çœ‹åˆ°ä¸»è¦å°±æ˜¯æ”¹äº† `_KEYS_TO_MODIFY_MAPPING` å˜é‡ï¼Œå…¶ä»–ä¿æŒä¸€è‡´å°±å®Œæˆäº†ã€‚
æœ‰ä¸ªå°ç»†èŠ‚ï¼Œåœ¨ `load_weights` å‡½æ•°é‡Œæˆ‘å¹¶æ²¡æœ‰åŠ è½½ `vision_tower` çš„å‚æ•°ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘å‘ç°è¿™ä¹ˆåšä¹‹åæ‰§è¡Œæ—¶ä¼šæŠ¥é”™ï¼Œ`vision_tower` å‚æ•°ä¸æ•°æ®ä¸åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´ `vision_tower` è¿˜åœ¨ CPUã€‚æˆ‘çŒœæµ‹æ˜¯å› ä¸º `load_weights` å‡½æ•°å·²ç»æ˜¯åœ¨æ¨¡å‹è¢« shard ä¹‹åï¼Œå„ä¸ª GPU åœ¨æ‰§è¡Œå¹¶å°†å‚æ•°åŠ è½½åˆ°è‡ªå·±çš„æ˜¾å­˜ä¸­çš„æ—¶å€™ã€‚å› æ­¤è¿™ä¸ªæ—¶å€™åŠ è½½ `vision_tower` å¦‚ä¸æŒ‡å®š `device` åˆ™ä¼šåŠ è½½åˆ° CPUï¼Œè‹¥æŒ‡å®š `cuda` ä¹Ÿä¸çŸ¥é“è¯¥åŠ è½½åˆ°å“ªä¸ª GPUï¼Œå› ä¸º `vision_tower` å¹¶æ²¡æœ‰å®ç° tensor parallelismï¼Œåªä¼šåŠ è½½åˆ°ä¸€ä¸ª GPU ä¸­ã€‚å› æ­¤è¿™ä¸ªæ—¶å€™å°±åº”è¯¥ç›´æ¥åœ¨ `__init__` å‡½æ•°ä¸­æ‰‹åŠ¨åŠ è½½ `vision_tower` çš„å‚æ•°ï¼Œç„¶åå†è®© `vllm` å»å†³å®šåŠ è½½åˆ°æŸä¸ª GPU ä¸­ã€‚å› æ­¤å®Œæ•´çš„ä»£ç åº”å½“å¦‚ä¸‹ï¼š

```python
# llavar.py

from vllm.model_executor.models.llava import LlavaForConditionalGeneration
from vllm.model_executor.model_loader.weight_utils import default_weight_loader

_KEYS_TO_MODIFY_MAPPING = {
    # Prioritize replacing "model.mm_projector" with "mm_projector" rather than language_model.mm_projector
    # The earlier the position in the mapping dictionary, the higher the priority
    "model.mm_projector": "mm_projector",
    "model.": "language_model.",
}


class LLavaRForConditionalGeneration(LlavaForConditionalGeneration):
    def __init__(
        self,
        config: LlavaConfig,
        vision_language_config: VisionLanguageConfig,
        cache_config: CacheConfig | None = None,
        quant_config: QuantizationConfig | None = None
    ) -> None:
        super().__init__(config, vision_language_config, cache_config, quant_config)

    delattr(self, "multi_modal_projector")
    self.mm_projector = nn.Linear(
        in_features=config.vision_config.hidden_size,
        out_features=config.text_config.hidden_size,
        bias=True,
    )
    self.vision_tower = CLIPVisionModel.from_pretrained(
        "openai/clip-vit-large-patch14-336",
        torch_dtype=torch.float16
    )

    def load_weights(self, weights: Iterable[Tuple[str, torch.Tensor]]):
        # only doing this for language model part for now.
        stacked_params_mapping = [
            # (param_name, shard_name, shard_id)
            ("qkv_proj", "q_proj", "q"),
            ("qkv_proj", "k_proj", "k"),
            ("qkv_proj", "v_proj", "v"),
            ("gate_up_proj", "gate_proj", 0),
            ("gate_up_proj", "up_proj", 1),
        ]
        params_dict = dict(self.named_parameters())
        for name, loaded_weight in weights:
            if "rotary_emb.inv_freq" in name:
                continue
            for key_to_modify, new_key in _KEYS_TO_MODIFY_MAPPING.items():
                if key_to_modify in name:
                    name = name.replace(key_to_modify, new_key)
            use_default_weight_loading = False
            if "vision" in name:
                if self.vision_tower is not None:
                    # We only do sharding for language model and
                    # not vision model for now.
                    use_default_weight_loading = True
            else:
                for (param_name, weight_name,
                     shard_id) in stacked_params_mapping:
                    if weight_name not in name:
                        continue
                    param = params_dict[name.replace(weight_name, param_name)]
                    weight_loader = param.weight_loader
                    weight_loader(param, loaded_weight, shard_id)
                    break
                else:
                    use_default_weight_loading = True
            if use_default_weight_loading:
                param = params_dict[name]
                weight_loader = getattr(param, "weight_loader",
                                        default_weight_loader)
                weight_loader(param, loaded_weight)
```

## æ³¨å†Œ `LlavaRForConditionalGeneration` æ¨¡å‹

å®˜æ–¹æ–‡æ¡£çš„æœ€åä¸€æ­¥å°±æ˜¯æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹ã€‚ç”±äº `vllm.LLM` æ¥å—çš„ `model` å‚æ•°åªæ˜¯ä¸€ä¸ª `str` ç±»å‹ï¼Œå› æ­¤ `vllm` æ˜¯ä»…æ¥å—ä¸€ä¸ªæ¨¡å‹åç§°æˆ–è·¯å¾„ï¼Œç„¶åå†å»å†…éƒ¨å®ä¾‹åŒ–ã€‚å› æ­¤ä¸ºäº†èƒ½å¤Ÿè®© `vllm` çŸ¥é“è‡ªå®šä¹‰æ¨¡å‹çš„å­˜åœ¨ï¼Œå°±éœ€è¦æ‰‹åŠ¨å»æ³¨å†Œæ¨¡å‹ã€‚æ³¨å†Œå¾ˆç®€å•ï¼Œç›´æ¥ç…§ç€å®˜æ–¹æ–‡æ¡£æŠ„å°±å¯ä»¥äº†ï¼š

```python
from vllm import ModelRegistry
from llavar import LlavaRForConditionalGeneration
ModelRegistry.register_model("LlavaRForConditionalGeneration", LlavaRForConditionalGeneration)
```

ä¸è¿‡åœ¨çœŸæ­£è¿è¡Œæ—¶ï¼Œè¿˜éœ€è¦ä¸º `LlavaRForConditionalGeneration` ç±»æ³¨å†Œå‡ ä¸ªè£…é¥°å™¨ã€‚å¦‚åŸå§‹çš„ [`LlavaForConditionalGeneration`](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/models/llava.py#L90) ç±»å°±æ³¨å†Œäº† 3 ä¸ªè£…é¥°å™¨ï¼Œåˆ†åˆ«æ˜¯ï¼š

- å¢åŠ å¤šæ¨¡æ€**ç‰¹å¾**è¾“å…¥(`@MULTIMODAL_REGISTRY.register_image_feature_input()`)çš„æ–¹æ³•ï¼Œ
- å¢åŠ å¤šæ¨¡æ€**åƒç´ **è¾“å…¥(`@MULTIMODAL_REGISTRY.register_image_pixel_input()`)çš„æ–¹æ³•ï¼Œ
- ä»¥åŠä¸€ä¸ªç»™å‡ºè¾“å…¥ç¤ºä¾‹(`@MULTIMODAL_REGISTRY.register_dummy_data(get_dummy_image_data)`)çš„æ–¹æ³•ã€‚

æˆ‘å¹¶æ²¡æœ‰ä»”ç»†çš„å»æŸ¥çœ‹è¿™äº›è£…é¥°å™¨æ–¹æ³•çš„ä½œç”¨ï¼Œä½†æ˜¯é€šè¿‡åœ¨å…¶ä»–éƒ¨åˆ†çš„å•æ­¥è°ƒè¯•æˆ‘çŒœæµ‹è¿™ 3 ä¸ªæ–¹æ³•çš„ä½œç”¨åˆ†åˆ«ä¸ºï¼š

- ä¸º `LlavaRForConditionalGeneration` æä¾›å›¾ç‰‡ç‰¹å¾è¾“å…¥æ”¯æŒï¼›
- ä¸º `LlavaRForConditionalGeneration` æä¾›å›¾ç‰‡åƒç´ è¾“å…¥æ”¯æŒï¼›
- åœ¨ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹ç”Ÿæˆä¹‹å‰ï¼Œ`vllm` ä¼šå…ˆä½¿ç”¨ `get_dummy_image_data` ç”Ÿæˆä¸€æ‰¹æ ·æœ¬æ•°æ®èµ°ä¸€éï¼ˆå¯èƒ½ç”¨äºæ”¶é›†ä¸€äº›æ˜¾å­˜ä½¿ç”¨ä¿¡æ¯ï¼Ÿï¼‰ï¼Œç„¶åæ‰ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œç”Ÿæˆã€‚

å‰ä¸¤ä¸ªè£…é¥°å™¨åº”è¯¥æ˜¯ LMM å¿…éœ€æ³¨å†Œå…¶ä¸­ä¸€ä¸ªçš„ï¼Œå¦åˆ™åº”è¯¥å°±æ— æ³•ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®ï¼›è€Œæœ€åä¸€ä¸ªåº”è¯¥æ˜¯æ‰€æœ‰æ¨¡å‹éƒ½éœ€è¦æ³¨å†Œçš„è£…é¥°å™¨ã€‚

é€šè¿‡æ³¨å†Œæ¨¡å‹è®© `vllm` çŸ¥é“è‡ªå®šä¹‰æ¨¡å‹çš„å­˜åœ¨ä¹‹åï¼Œè¿˜éœ€è¦è®© `vllm` çŸ¥é“ä»€ä¹ˆæ—¶å€™ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹ã€‚`vllm` å®ä¾‹åŒ–æ¨¡å‹æ˜¯é€šè¿‡ [`ModelRegistry`](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/model_loader/utils.py#L32) å®ç°çš„ï¼Œé€šè¿‡åœ¨ `ModelRegistry` é‡Œæ ¹æ®æ¡†æ¶åå­—æ‰¾çš„ï¼Œæ‰€ä»¥æ¡†æ¶åå­—å°±å†³å®šäº† `vllm` ç”¨ä»€ä¹ˆæ¨¡å‹ï¼Œè€Œæ¡†æ¶åå­—åˆæ˜¯æ¥æºäº [`model_config.hf_config`](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/model_loader/utils.py#L23)ã€‚çœ‹å˜é‡åå­—å¾ˆæ˜¾ç„¶ï¼Œ`model_config.hf_config` å°±æ˜¯ `huggingface` çš„ `config.json`ï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¦å°† `LLaVAR` checkpoint æ–‡ä»¶å¤¹ä¸‹ `config.json` çš„ `architectures` å­—æ®µä» `LlavaLlamaForCausalLM` æ”¹ä¸ºåˆšåˆšæ³¨å†Œçš„ `LlavaRForConditionalGeneration` å°±å¯ä»¥è®© `vllm` åŠ è½½äº†ã€‚

å®é™…ä¸Šï¼Œ`vllm` ä¸­ `model_config.hf_config` æ¥æºä¹Ÿçš„ç¡®å°±æ˜¯ `huggingface` çš„ `config.json`ï¼Œå¯ä»¥å‚è€ƒï¼š[link](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/config.py#L137)ã€‚

## LLaVAR Config é€‚é…

å¦‚ä¸Šæ‰€è¿°ï¼Œ`vllm` çš„ `model_config` å¾ˆå¤§ä¸€éƒ¨åˆ†æ¥è‡ªäº `huggingface` çš„ `config.json`ï¼Œå› æ­¤éœ€è¦ä¿è¯ `huggingface-transformers` èƒ½å¤Ÿæ­£ç¡®åœ°åŠ è½½ `config.json`ã€‚ç”±äº LLaVAR æœ¬è´¨ä¸Šæ˜¯ LLaVA-1.3ï¼Œæ˜¯åŸºäº LLaMA-1-13B çš„ LMMï¼Œå…¶å¼€å‘æ—¶çš„ `transformers` åº“ç‰ˆæœ¬è¾ƒè€ (4.28.0)ï¼Œè€Œ `vllm` æœ€æ–°ç‰ˆæœ¬éœ€è¦çš„ `transformers` åº“çš„ç‰ˆæœ¬è¦æ±‚åˆéå¸¸æ–° (4.41.2)ï¼Œå› æ­¤ä¼šå¯¼è‡´ä¸€äº›ç‰ˆæœ¬å†²çªï¼Œæ¯”å¦‚ `config.json` æ–‡ä»¶ä¸€äº›å­—æ®µå‘ç”Ÿäº†å˜åŒ–ï¼Œè¿™å°±éœ€è¦å…ˆå¯¹ `config.json` æ–‡ä»¶å­—æ®µè¿›è¡Œä¿®æ­£ã€‚

ä¿®æ­£æ–¹æ³•å…¶å®å°±æ˜¯æ ¹æ®æ–°ç‰ˆæœ¬ `transformers` åº“çš„ `LlavaConfig` çš„å„ä¸ªå­—æ®µï¼Œå¯¹è€ç‰ˆæœ¬çš„ `config.json` ä¿®æ”¹ã€åŒ¹é…å°±å®Œäº‹äº†ã€‚æœ€åæˆ‘å°† `LLaVAR` è‡ªå¸¦çš„ [`config.json`](https://huggingface.co/SALT-NLP/LLaVAR_delta/blob/main/config.json) æ”¹æˆäº†å¦‚ä¸‹ï¼š

```json
{
    "_name_or_path": "./llavar",
    "architectures": [
        "LlavaRForConditionalGeneration"
    ],
    "text_config": {
        "_name_or_path": "lmsys/vicuna-13b-v1.1",
        "architectures": [
            "LlamaForCausalLM"
        ],
        "max_position_embeddings": 2048,
        "model_type": "llama",
        "rms_norm_eps": 1e-06,
        "torch_dtype": "float16",
        "vocab_size": 32003,
        "hidden_act": "silu",
        "hidden_size": 5120,
        "bos_token_id": 1,
        "eos_token_id": 2,
        "intermediate_size": 13824,
        "pad_token_id": 0,
        "num_attention_heads": 40,
        "num_hidden_layers": 40,
        "tie_word_embeddings": false
    },
    "vision_config": {
        "hidden_size": 1024,
        "image_size": 336,
        "intermediate_size": 4096,
        "model_type": "clip_vision_model",
        "num_attention_heads": 16,
        "num_hidden_layers": 24,
        "patch_size": 14,
        "projection_dim": 768
    },
    "freeze_mm_mlp_adapter": false,
    "initializer_range": 0.02,
    "max_position_embeddings": 2048,
    "max_sequence_length": 2048,
    "mm_hidden_size": 1024,
    "mm_use_im_start_end": true,
    "mm_vision_tower": "openai/clip-vit-large-patch14-336",
    "model_type": "llava",
    "sep_image_conv_front": false,
    "tie_word_embeddings": false,
    "torch_dtype": "float16",
    "transformers_version": "4.28.0.dev0",
    "tune_mm_mlp_adapter": false,
    "use_cache": true,
    "use_mm_proj": true,
    "vision_feature_layer": -2,
    "vision_feature_select_strategy": "default"
}
```

å€¼å¾—ä¸€æçš„æ˜¯ï¼Œè¿™ä¸ª `config.json` ä¸­å…¶å®æœ‰éå¸¸å¤šçš„å­—æ®µå¹¶æ²¡æœ‰è¢« `vllm` ç”¨ä¸Šï¼Œæ¯”å¦‚ `mm_use_im_start_end`, `mm_hidden_size` ç­‰ç­‰ï¼Œå®é™…ä¸Šåªéœ€è¦ä¿®æ­£ä¸€äº›å¿…è¦å­—æ®µå¦‚ `text_config` å’Œ `vision_config` ä¸­çš„å­—æ®µå³å¯ã€‚`text_config` ç­‰è¿™äº›å­—æ®µæ˜¯å¿…é¡»è¢«ä¿®æ­£çš„ï¼Œæ¯”å¦‚æˆ‘å°±è¸©äº†å‘ï¼š`text_config` æ²¡æœ‰è®¾ç½®ï¼Œå¯¼è‡´ `LlamaConfig` é»˜è®¤ä½¿ç”¨ 7B çš„é…ç½®ï¼Œå› æ­¤ä¸ checkpoints çš„ 13B ä¸å¥‘åˆã€‚


## å®Œç»“
è‡³æ­¤å°±å·²ç»å¯ä»¥è·Ÿä½¿ç”¨ `llava-1.5-7b-hf` æ¨¡å‹ä¸€æ ·æ­£å¸¸ä½¿ç”¨ `LLaVAR` è¿›è¡Œå¤šå¡å¹¶è¡Œæ¨ç†äº†ã€‚

æœ¬æ–‡ä¸¥æ ¼æ„ä¹‰ä¸Šä»…æ¶‰åŠåˆ°äº†å®˜æ–¹æ–‡æ¡£çš„ç¬¬3ã€4æ­¥ï¼Œç¬¬1ã€2æ­¥ç•™ä½œåé¢æˆ‘é€‚é… Qwen-VL å’Œ CogVLM2 å†è°ˆã€‚

## åæ§½

æœ¬æ–‡è™½ç„¶çœ‹èµ·æ¥çŸ­ï¼Œä½†æ˜¯æ˜¯æˆ‘ç–¯ç‹‚è¯•é”™å¿« 10h çš„ç»“æœï¼Œä¸ºæ­¤æŸå¤±äº†ä¸€æ™šä¸Š + ä¸€ä¸‹åˆçš„è€å¤´ç¯ DLC æ—¶é—´ï¼ˆæ€¥æ­»æˆ‘äº†ï¼‰ã€‚å…¶å®è¯´æ˜¯ 10hï¼Œå®é™…ä¸Šæœ¬æ–‡æ¶‰åŠåˆ°çš„æ‰€æœ‰æ”¹åŠ¨åªèŠ±è´¹äº† 3hï¼Œå‰©ä¸‹ 7h éƒ½åœ¨è·Ÿ checkpoint ææ–—...

å› ä¸ºé‡åˆ°äº†ä»¥ä¸‹ä¸¤ä¸ªè®¤çŸ¥æ–¹é¢çš„é”™è¯¯ï¼š

1. ä¹‹å‰çœ‹åˆ° `LLaVA` å’Œ `LLaVAR` éƒ½æ˜¯ release **delta** ç‰ˆæœ¬çš„å‚æ•°ï¼Œå®Œå…¨æ²¡åœ¨æ„ã€‚ç›´åˆ°æ˜¨æ™šæ‹¿ç€ **delta** ç‰ˆæœ¬çš„ checkpoints åŠ è½½æ¨¡å‹ï¼Œç„¶åæ¨¡å‹è·‘èµ·æ¥ä¹‹åä¸€ç›´èƒ¡è¨€ä¹±è¯­ä¸è¯´äººè¯ï¼Œå¯¹ç€ `vllm` æºç ç¿»æ¥è¦†å»çœ‹ + google äº† 3h æ‰ååº”è¿‡æ¥è¿™ä¸ª **delta** ç‰ˆæœ¬æ˜¯ä»€ä¹ˆæ„æ€... å…¶å®å°±æ˜¯ä¸ºäº†ä¸è¿èƒŒ LLaMA çš„ LICENCEï¼Œå°†æœ€ç»ˆæ¨¡å‹çš„å‚æ•°è·Ÿ LLaMA æ¨¡å‹å‚æ•°åšäº†å‡æ³•å¾—åˆ°çš„å‚æ•°å°±æ˜¯ release å‡ºæ¥çš„ **delta** ç‰ˆæœ¬ã€‚ç„¶åå› ä¸ºè¿™è®¤çŸ¥ä¸Šçš„ç–å¿½å‘äº†æˆ‘ä¸€æ™šä¸Šçš„è€å¤´ç¯ DLC æ—¶é—´ã€‚
2. è¿™ä½æ›´æ˜¯é‡é‡çº§ã€‚æˆ‘å°† **delta** ç‰ˆæœ¬çš„å‚æ•°æ¢å¤ä¹‹åç›´æ¥å°†åŸæ¥çš„ `pytorch_model-00001-of-00003.bin` ç­‰æ¨¡å‹æ–‡ä»¶ååŠ äº†ä¸ªå‰ç¼€ `delta-` (`delta-pytorch_model-00001-of-00003.bin`)ï¼Œç»§ç»­æ”¾åœ¨ checkpoints æ–‡ä»¶å¤¹ä¸‹ï¼Œçœ‹ä¼¼æ²¡æœ‰é—®é¢˜ã€‚ç„¶è€Œè·‘èµ·æ¥ä¹‹åå‘ç°æ¨¡å‹ä¾ç„¶èƒ¡è¨€ä¹±è¯­ä¸è¯´äººè¯ï¼Œä½†æ˜¯ç”¨ [`LLaVAR` Github Repo](https://github.com/SALT-NLP/LLaVAR) çš„ä»£ç å´èƒ½å¤Ÿæ­£å¸¸è¯´è¯ï¼Œè¿˜èƒ½æœ‰è¿™ä¹ˆå¥‡æ€ªçš„äº‹ï¼Ÿäºæ˜¯åˆæ˜¯ 4h ç¿»æ¥è¦†å»çœ‹ `vllm` æºç  + google... æœ€ç»ˆå‘ç°é—®é¢˜å‡ºåœ¨äº† `delta-pytorch_model-00001-of-00003.bin` ä¸Šé¢ã€‚æˆ‘ä¹‹å‰çœ‹è¿‡ `huggingface` çš„ `.from_pretrained` æ–¹æ³•çš„åŠ è½½ checkpoints çš„é€»è¾‘ï¼Œæ˜¯å– `pytorch_model.bin.index.json` æ–‡ä»¶çš„æ‰€æœ‰ value çš„å¹¶é›†ä½œä¸ºåŠ è½½å¯¹è±¡ï¼Œéå¸¸åˆç†æ­£ç¡®ï¼Œç„¶åæˆ‘å°±ä»¥ä¸º `vllm` ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚ç›´åˆ°æˆ‘çœ‹åˆ°äº† [`vllm` çš„åŠ è½½é€»è¾‘](https://github.com/vllm-project/vllm/blob/0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1/vllm/model_executor/model_loader/loader.py#L156)ï¼Œå®ƒå±…ç„¶æ˜¯å°† checkpoints æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ `.bin` æ–‡ä»¶éƒ½åŠ è½½ï¼Ÿï¼Ÿï¼Ÿä¹Ÿå°±æ˜¯è¯´ä¹‹å‰çš„ `delta-pytorch_model-00001-of-00003.bin` æ–‡ä»¶ä¹Ÿè¢«åŠ è½½äº†ï¼Œæ‰€ä»¥æœ‰ä¸€äº›æ­£ç¡®çš„å‚æ•°å°±è¢« `delta` ç‰ˆæœ¬çš„å‚æ•°è¦†ç›–äº†ï¼Œä»è€Œå¯¼è‡´æ¨¡å‹ä¸€ç›´åœ¨èƒ¡è¨€ä¹±è¯­ä¸è¯´äººè¯ã€‚ç„¶åæˆ‘æŠŠ `delta` æ–‡ä»¶å…¨åˆ äº†ï¼Œæ¨¡å‹æ¨ç†ç»ˆäºæ­£å¸¸äº†ã€‚æ­¤æ—¶æˆ‘æƒ³ç€ä¸€æ•´ä¸ªè¢«ç”¨äº debug çš„å‡æœŸä¸‹åˆï¼Œåªæƒ³å¤§å–Šï¼šâ€œvllm æˆ‘ \*\*\*\*ï¼Œä½  \*\*\*\*ï¼â€

![çº¢æ¸©](../assets/img/mimes/hongwen.png)
